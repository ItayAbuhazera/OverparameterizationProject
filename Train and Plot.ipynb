{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# ---------------------- Filter to our wanted classes only ---------------------\n",
    "# Define the classes you want to keep (e.g., class 0 and class 1)\n",
    "# classes = ('car', 'frog', 'horse', 'ship')\n",
    "classes_to_keep = [1, 6, 7, 8]\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Function to filter the dataset by the specified classes\n",
    "def filter_dataset_by_class(data, labels, classes):\n",
    "    labels = labels.flatten()\n",
    "    mask = np.isin(labels, classes)\n",
    "    filtered_data = data[mask]\n",
    "    filtered_labels = labels[mask]\n",
    "    filtered_labels = np.array([classes.index(label) for label in filtered_labels])\n",
    "    return filtered_data, filtered_labels\n",
    "\n",
    "# Filter the training and testing datasets\n",
    "x_train_filtered, y_train_filtered = filter_dataset_by_class(x_train, y_train, classes_to_keep)\n",
    "x_test_filtered, y_test_filtered = filter_dataset_by_class(x_test, y_test, classes_to_keep)\n",
    "\n",
    "# Normalize the images to [-1, 1]\n",
    "x_train_filtered = (x_train_filtered.astype('float32') / 255.0 - 0.5) / 0.5\n",
    "x_test_filtered = (x_test_filtered.astype('float32') / 255.0 - 0.5) / 0.5\n",
    "# Center crop images to 28x28\n",
    "def center_crop(images, crop_size):\n",
    "    start = (images.shape[1] - crop_size) // 2\n",
    "    return images[:, start:start+crop_size, start:start+crop_size, :]\n",
    "\n",
    "# x_train_filtered = center_crop(x_train_filtered, 28)\n",
    "# x_test_filtered = center_crop(x_test_filtered, 28)\n",
    "\n",
    "# Create a custom Dataset class for PyTorch\n",
    "class KerasDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert numpy array to torch tensor\n",
    "        image = torch.tensor(image).permute(2, 0, 1)  # Convert from HWC to CHW format\n",
    "        label = torch.tensor(label).long()\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Create the `trainloader` and `testloader` equivalent using TensorFlow's tf.data API\n",
    "batch_size = 32\n",
    "trainset = KerasDataset(x_train_filtered, y_train_filtered)\n",
    "testset = KerasDataset(x_test_filtered, y_test_filtered)\n",
    "\n",
    "# Create trainloader (train dataset)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Create testloader (test dataset)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Example: Iterate through the filtered trainloader\n",
    "for i, (images, labels) in enumerate(trainloader):\n",
    "    print(f'Batch size: {images.size(0)}, Labels: {labels}')\n",
    "    if i == 3:\n",
    "      break\n",
    "\n",
    "print(trainset)\n",
    "print(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('car', 'frog', 'horse', 'ship')\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Net_36480():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(6, 10, 5)\n",
    "            self.fc1 = nn.Linear(10 * 5 * 5, 110)\n",
    "            self.fc2 = nn.Linear(110, 60)\n",
    "            self.fc3 = nn.Linear(60, 4)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    return Net()\n",
    "    \n",
    "def Net_10608():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)  # Conv layer with 6 output channels\n",
    "            self.pool = nn.MaxPool2d(2, 2)   # Max pooling layer with 2x2 window\n",
    "            self.conv2 = nn.Conv2d(6, 6, 5)  # Conv layer with 6 output channels\n",
    "            self.fc1 = nn.Linear(6 * 5 * 5, 40)  # Fully connected layer\n",
    "            self.fc2 = nn.Linear(40, 20)  # Fully connected layer\n",
    "            self.fc3 = nn.Linear(20, 4)   # Fully connected layer\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    return Net()\n",
    "\n",
    "def Net_13093():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(6, 8, 5)\n",
    "            self.fc1 = nn.Linear(8 * 5 * 5, 50)\n",
    "            self.fc2 = nn.Linear(50, 25)\n",
    "            self.fc3 = nn.Linear(25, 4)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    return Net()\n",
    "    \n",
    "def Net_15895():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)  # Conv layer with 6 output channels\n",
    "            self.pool = nn.MaxPool2d(2, 2)   # Max pooling layer with 2x2 window\n",
    "            self.conv2 = nn.Conv2d(6, 10, 5)  # Conv layer with 8 output channels\n",
    "            self.fc1 = nn.Linear(10 * 5 * 5, 50)  # Fully connected layer\n",
    "            self.fc2 = nn.Linear(50, 25)  # Fully connected layer\n",
    "            self.fc3 = nn.Linear(25, 4)   # Fully connected layer\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    return Net()\n",
    "\n",
    "\n",
    "def Net_39590():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(6, 10, 5)\n",
    "            self.fc1 = nn.Linear(10 * 5 * 5, 120)\n",
    "            self.fc2 = nn.Linear(120, 60)\n",
    "            self.fc3 = nn.Linear(60, 4)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    return Net()\n",
    "    \n",
    "def Net_23299():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)  # Conv layer with 6 output channels\n",
    "            self.pool = nn.MaxPool2d(2, 2)   # Max pooling layer with 2x2 window\n",
    "            self.conv2 = nn.Conv2d(6, 9, 5)  # Conv layer with 9 output channels\n",
    "            self.fc1 = nn.Linear(9 * 5 * 5, 80)  # Fully connected layer\n",
    "            self.fc2 = nn.Linear(80, 40)  # Fully connected layer\n",
    "            self.fc3 = nn.Linear(40, 4)   # Fully connected layer\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    return Net()\n",
    "\n",
    "def Net_27150():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)  # Conv layer with 6 output channels\n",
    "            self.pool = nn.MaxPool2d(2, 2)   # Max pooling layer with 2x2 window\n",
    "            self.conv2 = nn.Conv2d(6, 10, 5)  # Conv layer with 10 output channels\n",
    "            self.fc1 = nn.Linear(10 * 5 * 5, 80)  # Fully connected layer\n",
    "            self.fc2 = nn.Linear(80, 60)  # Fully connected layer\n",
    "            self.fc3 = nn.Linear(60, 4)   # Fully connected layer\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    return Net()\n",
    "\n",
    "def Net_45892():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(6, 12, 5)\n",
    "            self.fc1 = nn.Linear(12 * 5 * 5, 120)\n",
    "            self.fc2 = nn.Linear(120, 60)\n",
    "            self.fc3 = nn.Linear(60, 4)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    return Net()\n",
    "\n",
    "def Net_42052():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(6, 12, 5)\n",
    "            self.fc1 = nn.Linear(12 * 5 * 5, 110)\n",
    "            self.fc2 = nn.Linear(110, 58)\n",
    "            self.fc3 = nn.Linear(58, 4)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    return Net()\n",
    "\n",
    "def Net_30397():\n",
    "  class Net(nn.Module):\n",
    "      def __init__(self):\n",
    "          super().__init__()\n",
    "          self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "          self.pool = nn.MaxPool2d(2, 2)\n",
    "          self.conv2 = nn.Conv2d(6, 10, 5)\n",
    "          self.fc1 = nn.Linear(10 * 5 * 5, 92)\n",
    "          self.fc2 = nn.Linear(92, 55)\n",
    "          self.fc3 = nn.Linear(55, 4)\n",
    "\n",
    "      def forward(self, x):\n",
    "          x = self.pool(F.relu(self.conv1(x)))\n",
    "          x = self.pool(F.relu(self.conv2(x)))\n",
    "          x = torch.flatten(x, 1)\n",
    "          x = F.relu(self.fc1(x))\n",
    "          x = F.relu(self.fc2(x))\n",
    "          x = self.fc3(x)\n",
    "          return x\n",
    "  return Net()\n",
    "\n",
    "\n",
    "def Net_33370():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(6, 10, 5)\n",
    "            self.fc1 = nn.Linear(10 * 5 * 5, 100)\n",
    "            self.fc2 = nn.Linear(100, 60)\n",
    "            self.fc3 = nn.Linear(60, 4)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    return Net()\n",
    "\n",
    "def Net_16819():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)  # Keep conv1 as is\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "            # Reduce the number of output channels in conv2 slightly\n",
    "            self.conv2 = nn.Conv2d(6, 9, 5)  # Adjust conv2 to 11 output channels\n",
    "    \n",
    "            # Adjust the fully connected layers slightly to reduce parameters\n",
    "            self.fc1 = nn.Linear(9 * 5 * 5, 80)  # Adjust fc1 to 110 output units\n",
    "            self.fc2 = nn.Linear(80, 40)  # Adjust fc2 to 55 output units\n",
    "            self.fc3 = nn.Linear(40, 4)  # Keep fc3 as is\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "    return Net()\n",
    "\n",
    "def Net_3305():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)  # Keep conv1 as is\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "            # Reduce the number of output channels in conv2 slightly\n",
    "            self.conv2 = nn.Conv2d(6, 5, 5)  # Adjust conv2 to 11 output channels\n",
    "    \n",
    "            # Adjust the fully connected layers slightly to reduce parameters\n",
    "            self.fc1 = nn.Linear(5 * 5 * 5, 15)  # Adjust fc1 to 110 output units\n",
    "            self.fc2 = nn.Linear(15, 10)  # Adjust fc2 to 55 output units\n",
    "            self.fc3 = nn.Linear(10, 4)  # Keep fc3 as is\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "    return Net()\n",
    "\n",
    "def Net_5695():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)  # Keep conv1 as is\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "            # Reduce the number of output channels in conv2 slightly\n",
    "            self.conv2 = nn.Conv2d(6, 5, 5)  # Adjust conv2 to 11 output channels\n",
    "    \n",
    "            # Adjust the fully connected layers slightly to reduce parameters\n",
    "            self.fc1 = nn.Linear(5 * 5 * 5, 30)  # Adjust fc1 to 110 output units\n",
    "            self.fc2 = nn.Linear(30, 20)  # Adjust fc2 to 55 output units\n",
    "            self.fc3 = nn.Linear(20, 4)  # Keep fc3 as is\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "    return Net()\n",
    "\n",
    "def Net_62716():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)  # Keep conv1 as is\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "            # Reduce the number of output channels in conv2 slightly\n",
    "            self.conv2 = nn.Conv2d(6, 16, 5)  # Adjust conv2 to 11 output channels\n",
    "    \n",
    "            # Adjust the fully connected layers slightly to reduce parameters\n",
    "            self.fc1 = nn.Linear(16 * 5 * 5, 128)  # Adjust fc1 to 110 output units\n",
    "            self.fc2 = nn.Linear(128, 64)  # Adjust fc2 to 55 output units\n",
    "            self.fc3 = nn.Linear(64, 4)  # Keep fc3 as is\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "    return Net()\n",
    "\n",
    "def Net_54694():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)  # Keep conv1 as is\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "            # Reduce the number of output channels in conv2 slightly\n",
    "            self.conv2 = nn.Conv2d(6, 14, 5)  # Adjust conv2 to 11 output channels\n",
    "    \n",
    "            # Adjust the fully connected layers slightly to reduce parameters\n",
    "            self.fc1 = nn.Linear(14 * 5 * 5, 120)  # Adjust fc1 to 110 output units\n",
    "            self.fc2 = nn.Linear(120, 80)  # Adjust fc2 to 55 output units\n",
    "            self.fc3 = nn.Linear(80, 4)  # Keep fc3 as is\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "    return Net()\n",
    "\n",
    "def Net_75426():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)  # Keep conv1 as is\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "            # Reduce the number of output channels in conv2 slightly\n",
    "            self.conv2 = nn.Conv2d(6, 16, 5)  # Adjust conv2 to 11 output channels\n",
    "    \n",
    "            # Adjust the fully connected layers slightly to reduce parameters\n",
    "            self.fc1 = nn.Linear(16 * 5 * 5, 150)  # Adjust fc1 to 110 output units\n",
    "            self.fc2 = nn.Linear(150, 80)  # Adjust fc2 to 55 output units\n",
    "            self.fc3 = nn.Linear(80, 4)  # Keep fc3 as is\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "    return Net()\n",
    "\n",
    "# Mapping from parameter count to the corresponding network definition\n",
    "models_to_train = {\n",
    "    10608: Net_10608,\n",
    "    36480: Net_36480,\n",
    "    15895: Net_15895,\n",
    "    16819: Net_16819,\n",
    "    45892: Net_45892,\n",
    "    30397: Net_30397,\n",
    "    27150: Net_27150,\n",
    "    3305: Net_3305,\n",
    "    23299: Net_23299,\n",
    "    5695: Net_5695,\n",
    "    42052: Net_42052,\n",
    "    72426: Net_75426,\n",
    "    54694: Net_54694,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_train = {\n",
    "    10608: {'net': Net_10608, 'epochs': 50},\n",
    "    36480: {'net': Net_36480, 'epochs': 50},\n",
    "    15895: {'net': Net_15895, 'epochs': 50},\n",
    "    16819: {'net': Net_16819, 'epochs': 50},\n",
    "    45892: {'net': Net_45892, 'epochs': 50},\n",
    "    30397: {'net': Net_30397, 'epochs': 50},\n",
    "    27150: {'net': Net_27150, 'epochs': 50},\n",
    "    3305: {'net': Net_3305, 'epochs': 50},\n",
    "    23299: {'net': Net_23299, 'epochs': 50},\n",
    "    5695: {'net': Net_5695, 'epochs': 50},\n",
    "    42052: {'net': Net_42052, 'epochs': 50},\n",
    "}\n",
    "\n",
    "# Directory to save the models and results\n",
    "os.makedirs('result_noise', exist_ok=True)\n",
    "# Function to add noise to the labels\n",
    "def add_label_noise(labels, noise_ratio=0.15, num_classes=4):\n",
    "    noisy_labels = labels.clone()\n",
    "    num_noisy = int(noise_ratio * len(labels))\n",
    "    \n",
    "    # Randomly select indices to corrupt\n",
    "    noisy_indices = np.random.choice(len(labels), num_noisy, replace=False)\n",
    "    \n",
    "    # Replace the selected labels with random classes\n",
    "    noisy_labels[noisy_indices] = torch.randint(0, num_classes, size=(num_noisy,))\n",
    "    \n",
    "    return noisy_labels\n",
    "\n",
    "# Training function\n",
    "def train_model(model, trainloader, testloader, criterion, optimizer, n_epochs, save_path):\n",
    "    model.train()\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            # Add noise to the labels\n",
    "            noisy_labels = add_label_noise(labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, noisy_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Calculate and store train and test accuracy/loss\n",
    "        train_acc, train_loss = calculate_accuracy_and_loss(model, trainloader, criterion)\n",
    "        test_acc, test_loss = calculate_accuracy_and_loss(model, testloader, criterion, test=True)\n",
    "\n",
    "        train_accuracy.append(train_acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Train accuracy: {train_acc}, Test accuracy: {test_acc}, Train loss: {train_loss}, Test loss: {test_loss}')\n",
    "\n",
    "    # Save the model after training\n",
    "    new_model_path = os.path.join('result_noise', save_path.replace('.pth', '_noisy.pth'))\n",
    "    torch.save(model.state_dict(), new_model_path)\n",
    "\n",
    "    # Save the results as a CSV\n",
    "    new_results_path = os.path.join('result_noise', save_path.replace('.pth', '_noisy_results.csv'))\n",
    "    results = pd.DataFrame({\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'train_loss': train_losses,\n",
    "        'test_loss': test_losses\n",
    "    })\n",
    "    results.to_csv(new_results_path, index=False)\n",
    "    print(f'Saved model to {new_model_path} and results to {new_results_path}')\n",
    "\n",
    "def calculate_accuracy_and_loss(model, dataloader, criterion, test=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct // total\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "# Initialize the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Iterate over each model, create it from scratch, and train it with noisy labels\n",
    "for key, model_info in models_to_train.items():\n",
    "    print(f\"Processing model with {key} parameters\")\n",
    "\n",
    "    # Instantiate the model using the correct architecture\n",
    "    model = model_info['net']()  # Call the function to create the network\n",
    "    \n",
    "    # Initialize the optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.90)\n",
    "\n",
    "    # Train the model from scratch\n",
    "    train_model(model, trainloader, testloader, criterion, optimizer, model_info['epochs'], f'model_{key}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import pandas as pd\n",
    "net_dict = {\n",
    "    10608: Net_10608,\n",
    "    36480: Net_36480,\n",
    "    15895: Net_15895,\n",
    "    16819: Net_16819,\n",
    "    45892: Net_45892,\n",
    "    30397: Net_30397,\n",
    "    27150: Net_27150,\n",
    "    3305: Net_3305,\n",
    "    23299: Net_23299,\n",
    "    5695: Net_5695,\n",
    "    42052: Net_42052,\n",
    "    75426: Net_75426,\n",
    "    54694: Net_54694,\n",
    "    39590: Net_39590,\n",
    "    33370: Net_33370,\n",
    "    13093: Net_13093\n",
    "}\n",
    "# Define the paths and number of additional epochs for each model\n",
    "models_to_train = {\n",
    "    # '13093': {'path': '/cs_storage/itayab/PyCharmProjects/Rethinking_Generalization/src/results/13093/model_13093.pth', 'additional_epochs': 50},\n",
    "    # '33370': {'path': '/content/drive/MyDrive/MSc courses/OML project/4_class_cnn/33370/model_33370.pth', 'additional_epochs': 30},\n",
    "    # '36480': {'path': '/content/drive/MyDrive/MSc courses/OML project/4_class_cnn/36480/model_36480.pth', 'additional_epochs': 30},\n",
    "    # '39590': {'path': '/content/drive/MyDrive/MSc courses/OML project/4_class_cnn/39590/model_39590.pth', 'additional_epochs': 30},\n",
    "    # '3305': {'path': '/cs_storage/itayab/PyCharmProjects/Rethinking_Generalization/src/results/3305/model_3305.pth', 'additional_epochs': 50},\n",
    "    # '15895' : {'path': '/cs_storage/itayab/PyCharmProjects/Rethinking_Generalization/src/results/15895/model_15895.pth', 'additional_epochs': 50},\n",
    "    '16819' : {'path': '/cs_storage/itayab/PyCharmProjects/Rethinking_Generalization/src/results/16819/model_16819.pth', 'additional_epochs': 50}\n",
    "}\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_model(model, trainloader, testloader, criterion, optimizer, n_epochs, save_path):\n",
    "    model.train()\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Calculate and store train and test accuracy/loss\n",
    "        train_acc, train_loss = calculate_accuracy_and_loss(model, trainloader, criterion)\n",
    "        test_acc, test_loss = calculate_accuracy_and_loss(model, testloader, criterion, test=True)\n",
    "\n",
    "        train_accuracy.append(train_acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Train accuracy: {train_acc}, Test accuracy: {test_acc}, Train loss: {train_loss}, Test loss: {test_loss}')\n",
    "\n",
    "    # Save the model after training with a new name\n",
    "    new_model_path = save_path.replace('.pth', '_retrained.pth')\n",
    "    torch.save(model.state_dict(), new_model_path)\n",
    "\n",
    "    # Save the results as a CSV with a new name\n",
    "    new_results_path = save_path.replace('.pth', '_retrained_results.csv')\n",
    "    results = pd.DataFrame({\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'train_loss': train_losses,\n",
    "        'test_loss': test_losses\n",
    "    })\n",
    "    results.to_csv(new_results_path, index=False)\n",
    "    print(f'Saved model to {new_model_path} and results to {new_results_path}')\n",
    "\n",
    "def calculate_accuracy_and_loss(model, dataloader, criterion, test=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct // total\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "# Initialize the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Iterate over each model, load it, and continue training\n",
    "for key, model_info in models_to_train.items():\n",
    "    print(f\"Processing model with {key} parameters\")\n",
    "\n",
    "    # Convert the key to an integer and use it to get the correct Net class\n",
    "    param_count = int(key)\n",
    "    model = net_dict[param_count]()\n",
    "    print(model_info['path'])\n",
    "    # Load the state dictionary into the instantiated model\n",
    "    model.load_state_dict(torch.load(model_info['path']))\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.90)\n",
    "\n",
    "    # Continue training the model for the additional epochs\n",
    "    train_model(model, trainloader, testloader, criterion, optimizer, model_info['additional_epochs'], model_info['path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the directory containing the results\n",
    "directory = './results/'\n",
    "\n",
    "# Prepare lists to collect data\n",
    "param_counts = []\n",
    "final_train_accuracies = []\n",
    "final_test_accuracies = []\n",
    "final_train_losses = []\n",
    "final_test_losses = []\n",
    "\n",
    "# List all subdirectories\n",
    "subdirs = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "\n",
    "# Iterate over each subdirectory to find and process the CSV files\n",
    "for subdir in subdirs:\n",
    "    subdir_path = os.path.join(directory, subdir)\n",
    "\n",
    "    # Extract the number of parameters from the directory name\n",
    "    try:\n",
    "        num_params = int(subdir)\n",
    "        param_counts.append(num_params)\n",
    "    except ValueError:\n",
    "        # Skip directories that are not named after a number of parameters\n",
    "        continue\n",
    "\n",
    "    # Check for retrained results first\n",
    "    retrained_csv_path = os.path.join(subdir_path, f\"model_{subdir}_retrained_results.csv\")\n",
    "    original_csv_path = os.path.join(subdir_path, f\"results_{subdir}.csv\")\n",
    "\n",
    "    if os.path.exists(retrained_csv_path):\n",
    "        csv_path = retrained_csv_path\n",
    "    elif os.path.exists(original_csv_path):\n",
    "        csv_path = original_csv_path\n",
    "    else:\n",
    "        continue  # Skip if neither file exists\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Extract the final epoch's metrics\n",
    "    final_train_accuracies.append((100 - df['train_accuracy'].max()) / 100)\n",
    "    final_test_accuracies.append((100 - df['test_accuracy'][-5:].mean()) / 100)\n",
    "    final_train_losses.append(df['train_loss'][-30:].min())\n",
    "    final_test_losses.append(df['test_loss'][-30:].min())\n",
    "\n",
    "# Sort the results by the number of parameters\n",
    "sorted_indices = sorted(range(len(param_counts)), key=lambda i: param_counts[i])\n",
    "param_counts = np.array([param_counts[i] for i in sorted_indices])\n",
    "final_train_accuracies = [final_train_accuracies[i] for i in sorted_indices]\n",
    "final_test_accuracies = [final_test_accuracies[i] for i in sorted_indices]\n",
    "final_train_losses = [final_train_losses[i] for i in sorted_indices]\n",
    "final_test_losses = [final_test_losses[i] for i in sorted_indices]\n",
    "\n",
    "# Plotting Test/Train Error vs Number of Parameters without interpolation\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the actual test and train error data points\n",
    "plt.plot(param_counts, final_test_accuracies, '-', label='Test Error', color='blue', linewidth=2)\n",
    "plt.plot(param_counts, final_train_accuracies, '--', label='Train Error', color='blue', alpha=0.5)\n",
    "\n",
    "# Add the vertical line at 20,000 parameters for interpolation\n",
    "plt.axvline(x=20000, color='brown', linestyle='--', linewidth=2, label='Interpolation Point at 20K')\n",
    "\n",
    "# Highlight critical regime between 15k and 31k parameters\n",
    "critical_start = 10608\n",
    "critical_end = 33370\n",
    "plt.axvspan(critical_start, critical_end, color='orange', alpha=0.3, label='Critical Regime')\n",
    "\n",
    "# Add arrow and annotation for critical regime\n",
    "plt.annotate('Critical Regime', xy=(critical_start, 0.4), xytext=(critical_start + 2000, 0.5),\n",
    "             arrowprops=dict(facecolor='orange', shrink=0.05), fontsize=12, color='orange')\n",
    "\n",
    "# Customizing the plot\n",
    "plt.xlabel('Number of Parameters', fontsize=14)\n",
    "plt.ylabel('Error', fontsize=14)\n",
    "plt.ylim(-0.005, 0.16)\n",
    "plt.title('Test and train Error vs Number of Parameters', fontsize=16)\n",
    "plt.xticks(np.arange(0, param_counts.max() + 10000, step=10000))\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best', fontsize=12)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
